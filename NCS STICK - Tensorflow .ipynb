{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "\n",
    "# ****************************************************************************\n",
    "# \n",
    "# Modified from https://github.com/movidius/ncappzoo/blob/master/apps/live-image-classifier/live-image-classifier.py\n",
    "# See also http://blog.cavedu.com/category/ai-%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7/intel-movidius/\n",
    "\n",
    "# ****************************************************************************\n",
    "\n",
    "# Perform inference on a LIVE camera feed using DNNs on Intel® Movidius™ Neural Compute Stick (NCS)\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import numpy\n",
    "import ntpath\n",
    "import argparse\n",
    "\n",
    "import mvnc.mvncapi as mvnc\n",
    "\n",
    "\n",
    "ARGS                 = None  # Variable to store commandline arguments\n",
    "camera               = None  # OpenCV object for video capture\n",
    "\n",
    "# ---- STEP 1: Open the enumerated device and get a handle to it -------------\n",
    "\n",
    "def open_ncs_device():\n",
    "\n",
    "    # Look for enumerated NCS device(s); quit program if none found.\n",
    "    devices = mvnc.EnumerateDevices()\n",
    "    if len( devices ) == 0:\n",
    "        print( \"No devices found\" )\n",
    "        quit()\n",
    "\n",
    "    # Get a handle to the first enumerated device and open it\n",
    "    device = mvnc.Device( devices[0] )\n",
    "    device.OpenDevice()\n",
    "\n",
    "    return device\n",
    "\n",
    "# ---- STEP 2: Load a graph file onto the NCS device -------------------------\n",
    "\n",
    "def load_graph( device ):\n",
    "\n",
    "    # Read the graph file into a buffer\n",
    "    with open( ARGS.graph, mode='rb' ) as f:\n",
    "        blob = f.read()\n",
    "\n",
    "    # Load the graph buffer into the NCS\n",
    "    graph = device.AllocateGraph( blob )\n",
    "\n",
    "    return graph\n",
    "\n",
    "# ---- STEP 3: Pre-process the images ----------------------------------------\n",
    "\n",
    "def pre_process_image( frame ):\n",
    "\n",
    "    # Resize image [Image size is defined by choosen network, during training]\n",
    "    img = cv2.resize( frame, tuple( ARGS.dim ) )\n",
    "\n",
    "    # Extract/crop a section of the frame and resize it\n",
    "    height, width, channels = frame.shape\n",
    "    x1 = int( width / 3 )\n",
    "    y1 = int( height / 4 )\n",
    "    x2 = int( width * 2 / 3 )\n",
    "    y2 = int( height * 3 / 4 )\n",
    "\n",
    "    cv2.rectangle( frame, ( x1, y1 ) , ( x2, y2 ), ( 0, 255, 0 ), 2 )\n",
    "    img = frame[ y1 : y2, x1 : x2 ]\n",
    "\n",
    "    # Resize image [Image size if defined by choosen network, during training]\n",
    "    img = cv2.resize( img, tuple( ARGS.dim ) )\n",
    "\n",
    "    # Convert BGR to RGB [OpenCV reads image in BGR, some networks may need RGB]\n",
    "    if( ARGS.colormode == \"rgb\" ):\n",
    "        img = img[:, :, ::-1]\n",
    "\n",
    "    # Mean subtraction & scaling [A common technique used to center the data]\n",
    "    img = img.astype( numpy.float16 )\n",
    "    img = ( img - numpy.float16( ARGS.mean ) ) * ARGS.scale\n",
    "\n",
    "    return img\n",
    "\n",
    "# ---- STEP 4: Read & print inference results from the NCS -------------------\n",
    "\n",
    "def infer_image( graph, img, frame ):\n",
    "\n",
    "    # Load the image as a half-precision floating point array\n",
    "    graph.LoadTensor( img, 'user object' )\n",
    "\n",
    "    # Get the results from NCS\n",
    "    output, userobj = graph.GetResult()\n",
    "\n",
    "    # Find the index of highest confidence \n",
    "    top_prediction = output.argmax()\n",
    "\n",
    "    # Get execution time\n",
    "    inference_time = graph.GetGraphOption( mvnc.GraphOption.TIME_TAKEN )\n",
    "\n",
    "    print(  \"I am %3.1f%%\" % (100.0 * output[top_prediction] ) + \" confidant\"\n",
    "            + \" you are \" + labels[top_prediction]\n",
    "            + \" ( %.2f ms )\" % ( numpy.sum( inference_time ) ) )\n",
    "\n",
    "    # If a display is available, show the image on which inference was performed\n",
    "    if 'DISPLAY' in os.environ:\n",
    "        cv2.imshow( 'NCS live inference', frame )\n",
    "\n",
    "# ---- STEP 5: Unload the graph and close the device -------------------------\n",
    "\n",
    "def close_ncs_device( device, graph ):\n",
    "    graph.DeallocateGraph()\n",
    "    device.CloseDevice()\n",
    "    camera.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# ---- Main function (entry point for this script ) --------------------------\n",
    "\n",
    "def main():\n",
    "\n",
    "    device = open_ncs_device()\n",
    "    graph = load_graph( device )\n",
    "\n",
    "    # Main loop: Capture live stream & send frames to NCS\n",
    "    while( True ):\n",
    "        ret, frame = camera.read()\n",
    "        img = pre_process_image( frame )\n",
    "        infer_image( graph, img, frame )\n",
    "\n",
    "        # Display the frame for 5ms, and close the window so that the next\n",
    "        # frame can be displayed. Close the window if 'q' or 'Q' is pressed.\n",
    "        if( cv2.waitKey( 5 ) & 0xFF == ord( 'q' ) ):\n",
    "            break\n",
    "\n",
    "    close_ncs_device( device, graph )\n",
    "\n",
    "# ---- Define 'main' function as the entry point for this script -------------\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    parser = argparse.ArgumentParser(\n",
    "                         description=\"Image classifier using \\\n",
    "                         Intel® Movidius™ Neural Compute Stick.\" )\n",
    "\n",
    "    parser.add_argument( '-g', '--graph', type=str,\n",
    "                         default='../../caffe/GenderNet/graph',\n",
    "                         help=\"Absolute path to the neural network graph file.\" )\n",
    "\n",
    "    parser.add_argument( '-v', '--video', type=int,\n",
    "                         default=0,\n",
    "                         help=\"Index of your computer's V4L2 video device. \\\n",
    "                               ex. 0 for /dev/video0\" )\n",
    "\n",
    "    parser.add_argument( '-l', '--labels', type=str,\n",
    "                         default='../../data/age_gender/gender_categories.txt',\n",
    "                         help=\"Absolute path to labels file.\" )\n",
    "\n",
    "    parser.add_argument( '-M', '--mean', type=float,\n",
    "                         nargs='+',\n",
    "                         default=[78.42633776, 87.76891437, 114.89584775],\n",
    "                         help=\"',' delimited floating point values for image mean.\" )\n",
    "\n",
    "    parser.add_argument( '-S', '--scale', type=float,\n",
    "                         default=1,\n",
    "                         help=\"Absolute path to labels file.\" )\n",
    "\n",
    "    parser.add_argument( '-D', '--dim', type=int,\n",
    "                         nargs='+',\n",
    "                         default=[227, 227],\n",
    "                         help=\"Image dimensions. ex. -D 224 224\" )\n",
    "\n",
    "    parser.add_argument( '-c', '--colormode', type=str,\n",
    "                         default=\"rgb\",\n",
    "                         help=\"RGB vs BGR color sequence. This is network dependent.\" )\n",
    "\n",
    "    ARGS = parser.parse_args()\n",
    "\n",
    "    # Create a VideoCapture object\n",
    "    camera = cv2.VideoCapture( ARGS.video )\n",
    "\n",
    "    # Set camera resolution\n",
    "    camera.set( cv2.CAP_PROP_FRAME_WIDTH, 620 )\n",
    "    camera.set( cv2.CAP_PROP_FRAME_HEIGHT, 480 )\n",
    "\n",
    "    # Load the labels file\n",
    "    labels =[ line.rstrip('\\n') for line in\n",
    "              open( ARGS.labels ) if line != 'classes\\n']\n",
    "\n",
    "    main()\n",
    "\n",
    "# ==== End of file ==========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #!/usr/bin/python3\n",
    "\n",
    "# ****************************************************************************\n",
    "# M Mwembeshi - Modifying above script as follows:\n",
    "#  (a) Use NCSDK v2 instead of v1\n",
    "#  (b) Use InceptionV3 model (Tensorflow) instead of GenderNet (Caffe)\n",
    "#\n",
    "# Modified from https://github.com/movidius/ncappzoo/blob/master/apps/live-image-classifier/live-image-classifier.py\n",
    "# See also http://blog.cavedu.com/category/ai-%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7/intel-movidius/\n",
    "\n",
    "# ****************************************************************************\n",
    "\n",
    "# Perform inference on a LIVE camera feed using DNNs on Intel® Movidius™ Neural Compute Stick (NCS)\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import numpy\n",
    "import ntpath\n",
    "import argparse\n",
    "\n",
    "# import mvnc.mvncapi as mvnc    # Replaced with below NCSDK API V2 (https://movidius.github.io/ncsdk/ncapi/ncapi2/py_api/readme.html)\n",
    "from mvnc import mvncapi\n",
    "# import mvnc.mvncapi as mvnc\n",
    "\n",
    "ARGS                 = None  # Variable to store commandline arguments\n",
    "camera               = None  # OpenCV object for video capture\n",
    "\n",
    "# ---- STEP 1: Open the enumerated device and get a handle to it -------------\n",
    "\n",
    "def open_ncs_device(): \n",
    "    # MM - Updated entire function to align with NCSDK API V2 (https://movidius.github.io/ncsdk/ncapi/ncapi2/py_api/readme.html)\n",
    "    device_list = mvncapi.enumerate_devices()   # Get a list of available device identifiers\n",
    "    if len( device_list ) == 0:\n",
    "        print( \"No devices found\" )\n",
    "        quit()\n",
    "        \n",
    "        \n",
    "    device = mvncapi.Device(device_list[0]) # Get a handle to the first enumerated device and open it\n",
    "    device.open()\n",
    "\n",
    "    return device\n",
    "\n",
    "# ---- STEP 2: Load a graph file onto the NCS device -------------------------\n",
    "\n",
    "def load_graph( device ):\n",
    "\n",
    "    # Read the graph file into a buffer\n",
    "    with open( ARGS.graph, mode='rb' ) as f:\n",
    "        blob = f.read()\n",
    "\n",
    "    # Load the graph buffer into the NCS\n",
    "    graph = device.AllocateGraph( blob )\n",
    "\n",
    "    return graph\n",
    "\n",
    "# ---- STEP 3: Pre-process the images ----------------------------------------\n",
    "\n",
    "def pre_process_image( frame ):\n",
    "\n",
    "    # Resize image [Image size is defined by choosen network, during training]\n",
    "    img = cv2.resize( frame, tuple( ARGS.dim ) )\n",
    "\n",
    "    # Extract/crop a section of the frame and resize it\n",
    "    height, width, channels = frame.shape\n",
    "    x1 = int( width / 3 )\n",
    "    y1 = int( height / 4 )\n",
    "    x2 = int( width * 2 / 3 )\n",
    "    y2 = int( height * 3 / 4 )\n",
    "\n",
    "    cv2.rectangle( frame, ( x1, y1 ) , ( x2, y2 ), ( 0, 255, 0 ), 2 )\n",
    "    img = frame[ y1 : y2, x1 : x2 ]\n",
    "\n",
    "    # Resize image [Image size if defined by choosen network, during training]\n",
    "    img = cv2.resize( img, tuple( ARGS.dim ) )\n",
    "\n",
    "    # Convert BGR to RGB [OpenCV reads image in BGR, some networks may need RGB]\n",
    "    if( ARGS.colormode == \"rgb\" ):\n",
    "        img = img[:, :, ::-1]\n",
    "\n",
    "    # Mean subtraction & scaling [A common technique used to center the data]\n",
    "    img = img.astype( numpy.float16 )\n",
    "    img = ( img - numpy.float16( ARGS.mean ) ) * ARGS.scale\n",
    "\n",
    "    return img\n",
    "\n",
    "# ---- STEP 4: Read & print inference results from the NCS -------------------\n",
    "\n",
    "def infer_image( graph, img, frame ):\n",
    "\n",
    "    # Load the image as a half-precision floating point array\n",
    "    graph.LoadTensor( img, 'user object' )\n",
    "\n",
    "    # Get the results from NCS\n",
    "    output, userobj = graph.GetResult()\n",
    "\n",
    "    # Find the index of highest confidence \n",
    "    top_prediction = output.argmax()\n",
    "\n",
    "    # Get execution time\n",
    "    inference_time = graph.GetGraphOption( mvncapi.GraphOption.TIME_TAKEN )\n",
    "\n",
    "    print(  \"I am %3.1f%%\" % (100.0 * output[top_prediction] ) + \" confident\"\n",
    "            + \" you are \" + labels[top_prediction]\n",
    "            + \" ( %.2f ms )\" % ( numpy.sum( inference_time ) ) )\n",
    "\n",
    "    # If a display is available, show the image on which inference was performed\n",
    "    if 'DISPLAY' in os.environ:\n",
    "        cv2.imshow( 'NCS live inference', frame )\n",
    "\n",
    "# ---- STEP 5: Unload the graph and close the device -------------------------\n",
    "\n",
    "def close_ncs_device( device, graph ):\n",
    "    graph.destroy()\n",
    "    device.close()\n",
    "    device.destroy()\n",
    "    # graph.DeallocateGraph()  # MMM -replaced with above from \n",
    "    # device.CloseDevice()     # MMM -replaced with above from \n",
    "    camera.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# ---- Main function (entry point for this script ) --------------------------\n",
    "\n",
    "def main():\n",
    "\n",
    "    device = open_ncs_device()\n",
    "    graph = load_graph( device )\n",
    "\n",
    "    # Main loop: Capture live stream & send frames to NCS\n",
    "    while( True ):\n",
    "        ret, frame = camera.read()\n",
    "        img = pre_process_image( frame )\n",
    "        infer_image( graph, img, frame )\n",
    "\n",
    "        # Display the frame for 5ms, and close the window so that the next\n",
    "        # frame can be displayed. Close the window if 'q' or 'Q' is pressed.\n",
    "        if( cv2.waitKey( 5 ) & 0xFF == ord( 'q' ) ):\n",
    "            break\n",
    "\n",
    "    close_ncs_device( device, graph )\n",
    "\n",
    "# ---- Define 'main' function as the entry point for this script -------------\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    parser = argparse.ArgumentParser(\n",
    "                         description=\"Image classifier using \\\n",
    "                         Intel® Movidius™ Neural Compute Stick.\" )\n",
    "    # changed path to neural network graph for inceptionV3\n",
    "    parser.add_argument( '-g', '--graph', type=str,\n",
    "                         default='./graph',\n",
    "                         help=\"Absolute path to the neural network graph file.\" )\n",
    "\n",
    "    parser.add_argument( '-v', '--video', type=int,\n",
    "                         default=0,\n",
    "                         help=\"Index of your computer's video device. \\\n",
    "                               ex. 0 for /dev/video0\" )\n",
    "    # changed path and filename with labels\n",
    "    parser.add_argument( '-l', '--labels', type=str,\n",
    "                         default='./categories.txt',\n",
    "                         help=\"Absolute path to labels file.\" )\n",
    "\n",
    "    # changed (a) from float to int (b) changed to  mean [128,128,128]\n",
    "    parser.add_argument( '-M', '--mean', type=int,\n",
    "                         nargs='+',\n",
    "                         default=[128, 128, 128],\n",
    "                         help=\"',' delimited floating point values for image mean.\" )\n",
    "\n",
    "    parser.add_argument( '-S', '--scale', type=float,\n",
    "                         default=1,\n",
    "                         help=\"Absolute path to labels file.\" )\n",
    "    # changed dimensions to 299 x 299 to match inceptionV3\n",
    "    parser.add_argument( '-D', '--dim', type=int,\n",
    "                         nargs='+',\n",
    "                         default=[299, 299],\n",
    "                         help=\"Image dimensions. ex. -D 224 224\" )\n",
    "    # changed dimensions to 229 x 229 to match inceptionV3\n",
    "    parser.add_argument( '-c', '--colormode', type=str,\n",
    "                         default=\"rgb\",\n",
    "                         help=\"RGB vs BGR color sequence. This is network dependent.\" )\n",
    "\n",
    "    ARGS = parser.parse_args()\n",
    "\n",
    "    # Create a VideoCapture object\n",
    "    camera = cv2.VideoCapture( ARGS.video )\n",
    "\n",
    "    # Set camera resolution\n",
    "    camera.set( cv2.CAP_PROP_FRAME_WIDTH, 620 )\n",
    "    camera.set( cv2.CAP_PROP_FRAME_HEIGHT, 480 )\n",
    "\n",
    "    # Load the labels file\n",
    "    labels =[ line.rstrip('\\n') for line in\n",
    "              open( ARGS.labels ) if line != 'classes\\n']\n",
    "\n",
    "    main()\n",
    "\n",
    "# ==== End of file ==========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/movidius/ncappzoo/tree/master/apps/live-image-classifier\n",
    "python3 live-image-classifier.py --graph ../../tensorflow/inception/model/v3/graph --labels ../../tensorflow/inception/model/v3/label.txt --mean 127.5 --scale 0.00789 --dim 299 299 --colormode=\"RGB\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
